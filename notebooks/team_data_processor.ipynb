{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from scraping_utils import years, make_http_req\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_stats_url_template = 'https://www.basketball-reference.com/leagues/NBA_{}_standings.html'\n",
    "for year in years: \n",
    "    try:\n",
    "        file_path = f'../data/yearly_team_data/{year}.html' \n",
    "        # Create a new file, if it already exists, raise a FileExistsError\n",
    "        with open(file_path, 'x', encoding = 'utf-8') as f: \n",
    "            url = teams_stats_url_template.format(year)\n",
    "            response_html = make_http_req(url).text\n",
    "            f.write(str(response_html))\n",
    "    except FileExistsError:\n",
    "        # If the file already exists, we can simply continue\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_standings_tables(page_html : str):\n",
    "    \"\"\"\n",
    "    Extracts the standings table from the given HTML page. Strips the web page of\n",
    "    unnecessary information, return the relevant standings tables for the page.\n",
    "    :param page: HTML content of the web page.\n",
    "    :return: a 2-tuple of beautiful soup objects corresponding to the Eastern & Western conf.\n",
    "    standings table, respectively.\n",
    "    \"\"\"\n",
    "    soup : BeautifulSoup = BeautifulSoup(page_html, 'html.parser')\n",
    "\n",
    "    # Extract the specific tables containing the East / West Conference standings \n",
    "    # Clean each table to remove unnecessary qualitative data \n",
    "    east_standings_table = soup.find(id='divs_standings_E')\n",
    "    west_standings_table= soup.find(id='divs_standings_W')\n",
    "\n",
    "    \n",
    "    # Remove all table rows with the class thead - they contain unnecessary Division name data\n",
    "    for tr in east_standings_table.find_all('tr', class_='thead'):\n",
    "        tr.decompose()\n",
    "    for tr in west_standings_table.find_all('tr', class_='thead'):\n",
    "        tr.decompose()\n",
    "    \n",
    "    return east_standings_table, west_standings_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for year in years: \n",
    "    file_path = f'../data/yearly_team_data/{year}.html' \n",
    "    with open(file_path, 'r', encoding='utf-8') as f: \n",
    "        page_html = f.read()\n",
    "        east_standings_table, west_standings_table = clean_standings_tables(page_html)\n",
    "        \n",
    "        # Wrap the raw HTML in stringIO before parsing for error-free pandas reading\n",
    "        east_standings_df = pd.read_html(StringIO(str(east_standings_table)))[0]\n",
    "        west_standings_df = pd.read_html(StringIO(str(west_standings_table)))[0]\n",
    "\n",
    "        east_standings_df['Year'] = year\n",
    "        west_standings_df['Year'] = year\n",
    "        \n",
    "        # Add the teams to the corresponding dataframes - the team by default will be under \n",
    "        # the conference cols of the DFs\n",
    "\n",
    "        east_standings_df['Team'] = east_standings_df['Eastern Conference']\n",
    "        del east_standings_df['Eastern Conference']\n",
    "\n",
    "        west_standings_df['Team'] = west_standings_df['Western Conference']\n",
    "        del west_standings_df['Western Conference']\n",
    "        \n",
    "        dfs.extend([east_standings_df, west_standings_df])\n",
    "\n",
    "\n",
    "combined_yearly_team_df : pd.DataFrame= pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_yearly_team_df.tail(35)\n",
    "combined_yearly_team_df.to_csv('../data/team_data_1991-2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
