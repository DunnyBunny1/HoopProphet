{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipynb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_http_req\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_yearly_mvp_data\u001b[39m(years):\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    Downloads MVP for each given year and saves each into HTML files\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    Iterates through the list of years provided, scrapes the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    :raises RuntimeError: If encountering exceptions during URL request.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from utils.ipynb import make_http_req\n",
    "\n",
    "\n",
    "def initialize_yearly_mvp_data(years):\n",
    "    \"\"\"\n",
    "    Downloads MVP for each given year and saves each into HTML files\n",
    "    Iterates through the list of years provided, scrapes the\n",
    "    web page from the corresponding URL for that year, extracts the relevant\n",
    "    table data from the page's HTML, and saves the mvp table data into HTML\n",
    "    files in the corresponding folder.\n",
    "    If the file for a particular year already exists, skips that year's data.\n",
    "    :param years: List of years for which MVP data is to be downloaded.\n",
    "    :raises RuntimeError: If encountering exceptions during URL request.\n",
    "    \"\"\"\n",
    "    # Iterate through each year that we want to scrape data for\n",
    "    # Iterate through each type of data that we want to scrape data for:\n",
    "    # MVP data, player data, team data\n",
    "    url_template = 'https://www.basketball-reference.com/awards/awards_{}.html'\n",
    "    for year in years:\n",
    "        file_path = 'scraping_tools/yearly_mvp_data/{}.html'.format(year)\n",
    "        try:\n",
    "            # Create a new file, if it already exists, raise a FileExistsError\n",
    "            with open(file_path, 'x', encoding='utf-8') as f:\n",
    "                url = url_template.format(year)\n",
    "                # Try to make a GET request to the URL\n",
    "                try:\n",
    "                    response = make_http_req(url)\n",
    "                except (requests.exceptions.TooManyRedirects,\n",
    "                        requests.exceptions.RequestException,\n",
    "                        requests.exceptions.InvalidURL) as e:\n",
    "                    raise RuntimeError(\n",
    "                        f'Encountered {e} when making a URL request')\n",
    "                # Save the html table into a file in our yearly_mvp_data folder\n",
    "                mvp_table_html = extract_yearly_mvp_table(response.text)\n",
    "                # Write a string repr. of the page's HTML for the mvp table\n",
    "                # f.write(str(mvp_table_html))\n",
    "        except FileExistsError:\n",
    "            # If the file already exists, we can simply continue\n",
    "            continue\n",
    "\n",
    "\n",
    "def extract_yearly_mvp_table(page):\n",
    "    \"\"\"\n",
    "    Extracts the MVP table from the given HTML page. Strips the web page of\n",
    "    unnecessary information, return the relevant mvp table for the page.\n",
    "    :param page: HTML content of the web page.\n",
    "    :return: BeautifulSoup object containing the MVP table.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    # Remove the 0th table row - it contains unnecessary info for our data\n",
    "    soup.find('tr', class_='over_header').decompose()\n",
    "    # Extract the specific table containing MVP voting data\n",
    "    mvp_table = soup.find(id='mvp')\n",
    "    return mvp_table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
